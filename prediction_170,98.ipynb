{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting datasets to be interpreted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = pd.read_csv(\"data/ais_train.csv\", delimiter='|')\n",
    "X_sample.to_csv('data/ais_train_modified.csv', index=False)\n",
    "extra_vessels = pd.read_csv(\"data/vessels.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_vessels.to_csv('data/vessels_modified.csv', index=False)\n",
    "extra_ports = pd.read_csv(\"data/ports.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_ports.to_csv('data/ports_modified.csv', index=False)\n",
    "extra_schedules = pd.read_csv(\"data/schedules_to_may_2024.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_schedules.to_csv('data/schedules_to_may_2024_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_evaluation = pd.read_csv(\"data/ais_test.csv\",)\n",
    "extra_ports = pd.read_csv(\"data/ports_modified.csv\")\n",
    "extra_vessels = pd.read_csv(\"data/vessels_modified.csv\")\n",
    "extra_schedules = pd.read_csv(\"data/schedules_to_may_2024_modified.csv\")\n",
    "X_original = pd.read_csv(\"data/ais_train_modified.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing current data into previous data for the train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def past_course(original):\n",
    "    original=original.reset_index()\n",
    "\n",
    "    original['prev_lat'] = original['latitude'].shift(1).fillna(original['latitude'].iloc[0])\n",
    "    original['prev_lon'] = original['longitude'].shift(1).fillna(original['longitude'].iloc[0])\n",
    "    original['time_2'] = original['time'].shift(1).fillna(original['time'].iloc[0])\n",
    "    original['cog'] = original['cog'].shift(1)\n",
    "    original['sog'] = original['sog'].shift(1)\n",
    "    original['rot'] = original['rot'].shift(1)\n",
    "    original['heading'] = original['heading'].shift(1)\n",
    "    original['navstat'] = original['navstat'].shift(1)\n",
    "    original.loc[0,['cog','sog','rot','heading','navstat']]=[0,0,0,0,0]\n",
    "\n",
    "    return original\n",
    "\n",
    "def adapting_training_data(original):\n",
    "    ships = original['vesselId'].unique()\n",
    "    new = original.copy()\n",
    "    new['time'] = pd.to_datetime(new['time'])\n",
    "    new['prev_lat']=original['latitude']\n",
    "    new['prev_lon']=original['longitude']\n",
    "    new['time_2'] = new['time']\n",
    "    new = new.reset_index()\n",
    "    final = pd.DataFrame(columns=new.columns)\n",
    "    for c in ships:\n",
    "        one_ship = new[new['vesselId'] == c].copy()\n",
    "        new_filtered = past_course(one_ship)\n",
    "        final = pd.concat([final, new_filtered], ignore_index=True)\n",
    "    final = final.sort_values(by='index')\n",
    "    final = final.drop(['index'],axis=1)\n",
    "    final = final.reset_index(drop=True)\n",
    "    final = final.drop(['level_0'],axis=1)\n",
    "    final['time_dif'] = (final['time']-final['time_2']).dt.total_seconds()/3600\n",
    "    return(final)\n",
    "\n",
    "def adapting_test_data (evaluation,training):\n",
    "    evalu=evaluation.copy()\n",
    "    evalu['time'] = pd.to_datetime(evalu['time'])\n",
    "    evalu['time_2'] = evalu['time']\n",
    "    evalu[['cog','sog','heading','navstat','latitude','longitude']] = 0.1\n",
    "    evalu['etaRaw'] = evalu['time']\n",
    "    evalu['portId'] ='1'\n",
    "\n",
    "    train=training.copy()\n",
    "    train['time'] = pd.to_datetime(train['time'])\n",
    "    train['time_2'] = train['time']\n",
    "    evalu = evalu.drop(['ID','scaling_factor'],axis=1)\n",
    "\n",
    "    final = pd.concat([train, evalu], ignore_index=True)\n",
    "    x = adapting_training_data(final)\n",
    "    ships = x['vesselId'].unique()\n",
    "    evalu = x.iloc[len(train):]\n",
    "    ships = evalu['vesselId'].unique()\n",
    "    final = final.iloc[0:0]\n",
    "    for c in ships:\n",
    "        filtered = evalu[evalu['vesselId'] == c].copy()\n",
    "        filtered = filtered.reset_index()\n",
    "        filtered[['time_2','cog','sog','rot','heading','navstat','etaRaw','prev_lat','prev_lon']] = filtered.iloc[0][['time_2','cog','sog','rot','heading','navstat','etaRaw','prev_lat','prev_lon']]\n",
    "        final = pd.concat([final,filtered], ignore_index=True)\n",
    "    \n",
    "    final['time_dif'] = (final['time']-final['time_2']).dt.total_seconds()/3600\n",
    "    final = final.sort_values(by='index')\n",
    "    final = final.drop(['index'],axis=1)\n",
    "    final = final.reset_index(drop=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  adapting_test_data(X_evaluation,X_original)\n",
    "train = adapting_training_data(X_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['time','etaRaw','vesselId','portId','time_2'],axis=1)\n",
    "t = test.copy()\n",
    "t = t.drop(['time','etaRaw','vesselId','portId','time_2','latitude','longitude'],axis=1)\n",
    "train_lon = train.loc[:,['longitude']]\n",
    "train_lat = train.loc[:,['latitude']]\n",
    "train = train.drop(['latitude','longitude'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_lon = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_lon.fit(train, train_lon.values.ravel())\n",
    "forest_lat = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_lat.fit(train, train_lat.values.ravel())\n",
    "longitude_predicted = forest_lon.predict(t)\n",
    "latitude_predicted = forest_lat.predict(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_prediction = pd.DataFrame({'longitude_predicted':longitude_predicted,'latitude_predicted':latitude_predicted})\n",
    "forest_prediction = forest_prediction.reset_index()\n",
    "forest_prediction.rename(columns={'index': 'ID'}, inplace=True)\n",
    "forest_prediction.to_csv('data/forest_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
