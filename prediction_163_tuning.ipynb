{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapting datasets to be interpreted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = pd.read_csv(\"data/ais_train.csv\", delimiter='|')\n",
    "X_sample.to_csv('data/ais_train_modified.csv', index=False)\n",
    "extra_vessels = pd.read_csv(\"data/vessels.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_vessels.to_csv('data/vessels_modified.csv', index=False)\n",
    "extra_ports = pd.read_csv(\"data/ports.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_ports.to_csv('data/ports_modified.csv', index=False)\n",
    "extra_schedules = pd.read_csv(\"data/schedules_to_may_2024.csv\", on_bad_lines='skip', delimiter='|')\n",
    "extra_schedules.to_csv('data/schedules_to_may_2024_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_evaluation = pd.read_csv(\"data/ais_test.csv\",)\n",
    "extra_ports = pd.read_csv(\"data/ports_modified.csv\")\n",
    "extra_vessels = pd.read_csv(\"data/vessels_modified.csv\")\n",
    "extra_schedules = pd.read_csv(\"data/schedules_to_may_2024_modified.csv\")\n",
    "X_original = pd.read_csv(\"data/ais_train_modified.csv\")\n",
    "X_original['etaRaw'] = pd.to_datetime('2024-' + X_original['etaRaw']+ ':00', format='%Y-%m-%d %H:%M:%S',errors='coerce')\n",
    "X_original = X_original.dropna(subset=['etaRaw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing current data into previous data for the train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def past_course(original):\n",
    "    original=original.reset_index()\n",
    "\n",
    "    original['prev_lat'] = original['latitude'].shift(1).fillna(original['latitude'].iloc[0])\n",
    "    original['prev_lon'] = original['longitude'].shift(1).fillna(original['longitude'].iloc[0])\n",
    "    original['time_2'] = original['time'].shift(1).fillna(original['time'].iloc[0])\n",
    "    original['cog'] = original['cog'].shift(1)\n",
    "    original['sog'] = original['sog'].shift(1)\n",
    "    original['rot'] = original['rot'].shift(1)\n",
    "    original['heading'] = original['heading'].shift(1)\n",
    "    original['navstat'] = original['navstat'].shift(1)\n",
    "    original.loc[0,['cog','sog','rot','heading','navstat']]=[0,0,0,0,0]\n",
    "\n",
    "    return original\n",
    "\n",
    "def adapting_training_data(original):\n",
    "    ships = original['vesselId'].unique()\n",
    "    new = original.copy()\n",
    "    new['time'] = pd.to_datetime(new['time'])\n",
    "    new['prev_lat']=original['latitude']\n",
    "    new['prev_lon']=original['longitude']\n",
    "    new['time_2'] = new['time']\n",
    "    new = new.reset_index()\n",
    "    final = pd.DataFrame(columns=new.columns)\n",
    "    for c in ships:\n",
    "        one_ship = new[new['vesselId'] == c].copy()\n",
    "        new_filtered = past_course(one_ship)\n",
    "        final = pd.concat([final, new_filtered], ignore_index=True)\n",
    "    final = final.sort_values(by='index')\n",
    "    final = final.drop(['index'],axis=1)\n",
    "    final = final.reset_index(drop=True)\n",
    "    final = final.drop(['level_0'],axis=1)\n",
    "    final['time_dif'] = (final['time']-final['time_2']).dt.total_seconds()/3600\n",
    "    return(final)\n",
    "\n",
    "def adapting_test_data (evaluation,training):\n",
    "    evalu=evaluation.copy()\n",
    "    evalu['time'] = pd.to_datetime(evalu['time'])\n",
    "    evalu['time_2'] = evalu['time']\n",
    "    evalu[['cog','sog','heading','navstat','latitude','longitude']] = 0.1\n",
    "    evalu['etaRaw'] = evalu['time']\n",
    "    evalu['portId'] ='1'\n",
    "\n",
    "    train=training.copy()\n",
    "    train['time'] = pd.to_datetime(train['time'])\n",
    "    train['time_2'] = train['time']\n",
    "    evalu = evalu.drop(['ID','scaling_factor'],axis=1)\n",
    "\n",
    "    final = pd.concat([train, evalu], ignore_index=True)\n",
    "    x = adapting_training_data(final)\n",
    "    ships = x['vesselId'].unique()\n",
    "    last_one = pd.DataFrame(columns=x.columns)\n",
    "    for c in ships:\n",
    "        one_ship = x[x['vesselId'] == c].copy()\n",
    "        one_ship=one_ship.reset_index()\n",
    "        one_ship['etaRaw'] = one_ship['etaRaw'].shift(1)\n",
    "        one_ship['portId'] = one_ship['portId'].shift(1)\n",
    "        last_one = pd.concat([last_one, one_ship], ignore_index=True)\n",
    "    last_one = last_one.sort_values(by='index')\n",
    "    last_one = last_one.drop(['index'],axis=1)\n",
    "    last_one = last_one.reset_index(drop=True)\n",
    "    evalu = last_one.iloc[len(train):]\n",
    "    ships = evalu['vesselId'].unique()\n",
    "    final = final.iloc[0:0]\n",
    "    for c in ships:\n",
    "        filtered = evalu[evalu['vesselId'] == c].copy()\n",
    "        filtered = filtered.reset_index()\n",
    "        filtered[['time_2','cog','sog','rot','heading','navstat','etaRaw','prev_lat','prev_lon','portId']] = filtered.iloc[0][['time_2','cog','sog','rot','heading','navstat','etaRaw','prev_lat','prev_lon','portId']]\n",
    "        final = pd.concat([final,filtered], ignore_index=True)\n",
    "    \n",
    "    final['time_dif'] = (final['time']-final['time_2']).dt.total_seconds()/3600\n",
    "    final = final.sort_values(by='index')\n",
    "    final = final.drop(['index'],axis=1)\n",
    "    final = final.reset_index(drop=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  adapting_test_data(X_evaluation,X_original)\n",
    "train = adapting_training_data(X_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['time_to_destiny'] = (train['etaRaw']-train['time']).dt.total_seconds()/3600\n",
    "test['time_to_destiny'] = (test['etaRaw']-test['time']).dt.total_seconds()/3600\n",
    "extra_ports.rename(columns={'latitude': 'port_lat','longitude': 'port_lon'}, inplace=True)\n",
    "extra_ports = extra_ports.drop(['name','portLocation','UN_LOCODE','countryName','ISO'],axis=1)\n",
    "train = pd.merge(train, extra_ports, on='portId', how='inner')\n",
    "test = pd.merge(test, extra_ports, on='portId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full = test.copy()\n",
    "test_full = test_full.drop(['cog','sog','rot','heading','navstat','time','etaRaw','vesselId','portId','time_2','latitude','longitude'],axis=1)\n",
    "train_full = train.copy()\n",
    "train_full = train.drop(['cog','sog','rot','heading','navstat','time','etaRaw','vesselId','portId','time_2'],axis=1)\n",
    "train_lon = train_full.loc[:,['longitude']]\n",
    "train_lat = train_full.loc[:,['latitude']]\n",
    "train_full = train_full.drop(['latitude','longitude'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# model definition\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Configuración de la búsqueda en cuadrícula para train_lon\n",
    "grid_search_lon = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_lon.fit(train_full, train_lon)\n",
    "\n",
    "# Configuración de la búsqueda en cuadrícula para train_lat\n",
    "grid_search_lat = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_lat.fit(train_full, train_lat)\n",
    "\n",
    "# Resultados para train_lon\n",
    "print(\"Mejores parámetros para train_lon:\", grid_search_lon.best_params_)\n",
    "print(\"Mejor puntuación para train_lon:\", grid_search_lon.best_score_)\n",
    "\n",
    "# Resultados para train_lat\n",
    "print(\"Mejores parámetros para train_lat:\", grid_search_lat.best_params_)\n",
    "print(\"Mejor puntuación para train_lat:\", grid_search_lat.best_score_)\n",
    "\n",
    "# Modelos ajustados con los mejores parámetros\n",
    "best_model_lon = grid_search_lon.best_estimator_\n",
    "best_model_lat = grid_search_lat.best_estimator_\n",
    "joblib.dump(best_model_lon, 'best_forest_lon.pkl')\n",
    "\n",
    "# Guarda el modelo de latitud\n",
    "joblib.dump(best_model_lat, 'best_forest_lat.pkl')\n",
    "# Predicción en el conjunto de prueba\n",
    "longitude_predicted = best_model_lon.predict(test_full)\n",
    "latitude_predicted = best_model_lat.predict(test_full)\n",
    "forest_prediction = pd.DataFrame({'longitude_predicted':longitude_predicted,'latitude_predicted':latitude_predicted})\n",
    "forest_prediction = forest_prediction.reset_index()\n",
    "forest_prediction.rename(columns={'index': 'ID'}, inplace=True)\n",
    "forest_prediction.to_csv('data/forest_prediction_extra_opt.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
